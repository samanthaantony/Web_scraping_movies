{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request, urllib.parse, urllib.error\n",
    "import requests\n",
    "import re\n",
    "import csv\n",
    "import ssl\n",
    "import collections\n",
    "import itertools\n",
    "import sqlite3\n",
    "from math import*\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd \n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignore SSL certificate errors\n",
    "ctx = ssl.create_default_context()\n",
    "ctx.check_hostname = False\n",
    "ctx.verify_mode = ssl.CERT_NONE\n",
    "#we need to use a user agent here, because metacritics does not accept bots\n",
    "headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/70.0.3538.77 Safari/537.36'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove all html symbols and get text\n",
    "def tag_removal(text):\n",
    "    \"\"\"Remove html tags from a string\"\"\"\n",
    "    import re\n",
    "    clean = re.compile('<.*?>')\n",
    "    return re.sub(clean,\"\", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine(list1,list2):#combines 2 list\n",
    "    return [x + [y[1]] for (x, y) in zip(list1, list2)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Imdb_Names():\n",
    "    url_imdb = 'http://www.imdb.com/chart/top' #url for top Imdb movies\n",
    "    response = requests.get(url_imdb)\n",
    "    soup = BeautifulSoup(response.text, 'lxml')\n",
    "    movies = soup.select('td.titleColumn')#reference to movie title\n",
    "    top_movies = movies[:50] #here we get the top 50 movies we want\n",
    "    imdb = []\n",
    "    n = 0\n",
    "    for index in range(0, len(top_movies)):\n",
    "        n = n + 1\n",
    "        movie_detail = movies[index].get_text()\n",
    "        #get movie index, title and year in text format\n",
    "        movie = (' '.join(movie_detail.split()).replace('.', ''))#remove period after index\n",
    "        movie_title = movie[len(str(index))+1:-7]#removes year at the end\n",
    "        data = [n,movie_title]#list of index and movie title\n",
    "        imdb.append(data) #appends to empty list imdb\n",
    "    return imdb  \n",
    "        \n",
    "\n",
    "def Imdb_Links():\n",
    "    #now we need to click into each movie name in order to see detailed information\n",
    "    #so we need to extract all the urls\n",
    "    url_imdb = 'https://www.imdb.com/chart/top'#url for top Imdb movies\n",
    "    response = requests.get(url_imdb)\n",
    "    soup = BeautifulSoup(response.text, 'lxml')\n",
    "    links = soup.select('td.titleColumn a')#reference to movie link\n",
    "    top_50_links = links[:50]\n",
    "    imdb_movie_links = []\n",
    "    for a in top_50_links:\n",
    "        hyperlink = a.attrs.get('href')\n",
    "        links = 'https://www.imdb.com'+hyperlink#combine to get complete url\n",
    "        imdb_movie_links.append(links)\n",
    "    return imdb_movie_links #returns a list of all the movie links   \n",
    "\n",
    "def Fetch_Genre_For_Dict():\n",
    "    movie_genre = []\n",
    "    n = 0\n",
    "    for url in Imdb_Links():\n",
    "        n = n + 1\n",
    "        page = requests.get(url, headers = headers)\n",
    "        soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "        ref_genre = soup.find_all('div', class_ = 'see-more inline canwrap')[1]#reference to movie genre\n",
    "        ref_genre_text = ref_genre.find_all('a')#reference to genre text\n",
    "        for i in range(0,len(ref_genre_text)):\n",
    "            genre = tag_removal(str(ref_genre_text[i]).replace(' ','').lower())\n",
    "            #cleaning and replace space with no space as well as convert to lowercase\n",
    "            movie_genre.append(genre)#append genre into the empty genre list\n",
    "    return movie_genre    \n",
    " \n",
    "\n",
    "def Imdb_Dict(my_list): \n",
    "    count = {} #empty dictionary\n",
    "    for j in my_list: \n",
    "        count[j] = count.get(j, 0) + 1 \n",
    "        #if element not present add the count as 0 else increment count by 1\n",
    "    return count\n",
    "\n",
    "def Fetch_Genre_CSV():\n",
    "    movie_genre = []\n",
    "    n = 0\n",
    "    for url in Imdb_Links():\n",
    "        n = n + 1\n",
    "        page = requests.get(url, headers = headers)\n",
    "        soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "        #we are using the html parser in bs4 to read all the html files on the webpage\n",
    "        ref_genre = soup.find_all('div', class_ = 'see-more inline canwrap')[1]#reference to movie genre\n",
    "        ref_genre_text = ref_genre.find_all('a')#reference to genre text\n",
    "        ref_genre_remove_tag = tag_removal(str(ref_genre_text).strip())\n",
    "        #remove square brackets\n",
    "        ref_genre_remove_brackets = (' '.join(ref_genre_remove_tag.split()).replace('[', '').replace(']', ''))\n",
    "        data = [n,ref_genre_remove_brackets]#list of index and movie genre\n",
    "        movie_genre.append(data)\n",
    "    return movie_genre    \n",
    "\n",
    " \n",
    "\n",
    "def IMDB():\n",
    "    imdb = []\n",
    "    imdb = combine(Imdb_Names(),Fetch_Genre_CSV())#combine movie names and genre's fetched in a list\n",
    "    return imdb\n",
    "\n",
    "def Imdb_Csv():    \n",
    "    filename = \"Top50_Imdb_movie.csv\"\n",
    "    headers = ['number' ,'name', 'genre']\n",
    "    with open(filename,'w',newline='') as f:  \n",
    "        w = csv.writer(f, headers)  \n",
    "        w.writerow(headers)\n",
    "        w.writerows(IMDB())\n",
    "    \n",
    "    \n",
    "    print(\"Imdb_CSV written!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rotten_Tomatoes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Rotten_Tomatoes_Names():\n",
    "    rotten_tomatoes = []\n",
    "    n = 0 \n",
    "    url_rotten_tomatoes = 'https://www.rottentomatoes.com/top/bestofrt/'\n",
    "    response = requests.get(url_rotten_tomatoes)\n",
    "    soup = BeautifulSoup(response.text, 'lxml')\n",
    "    movies = soup.select('table.table a')\n",
    "    final_movies = movies[:50]\n",
    "    for index in range(0, len(final_movies)): \n",
    "        n = n + 1\n",
    "        movie_string = movies[index].get_text()\n",
    "        movie = (' '.join(movie_string.split()).replace('.', ''))\n",
    "        data = [n,movie]\n",
    "        rotten_tomatoes.append(data)\n",
    "    return rotten_tomatoes  \n",
    "   \n",
    "\n",
    "def Rotten_Tomatoes_Links():\n",
    "    n = 0\n",
    "    url_rotten_tomatoes = 'https://www.rottentomatoes.com/top/bestofrt/'\n",
    "    response = requests.get(url_rotten_tomatoes)\n",
    "    soup = BeautifulSoup(response.text, 'lxml')\n",
    "    movie_links = soup.select('table.table a')\n",
    "    imdb_top_50_links = movie_links[:50]\n",
    "    movie_links = []\n",
    "    for a in imdb_top_50_links:\n",
    "        n = n + 1\n",
    "        links = a.attrs.get('href')\n",
    "        url = 'https://www.rottentomatoes.com'+links\n",
    "        movie_links.append(url)\n",
    "    return movie_links    \n",
    "\n",
    "def Genre_Dict():\n",
    "    movie_genre = []\n",
    "    n = 0\n",
    "    for url in Rotten_Tomatoes_Links():\n",
    "        n = n + 1\n",
    "        page = requests.get(url, headers = headers)\n",
    "        soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "        ref_genre_text = soup.find('div', class_ = 'meta-value genre').text\n",
    "        cleaned_genre = ' '.join(ref_genre_text).replace(',','').replace(' ','').replace('and','\\n')\n",
    "        genre2 = cleaned_genre.split()\n",
    "        movie_genre.append(genre2)\n",
    "    return movie_genre    \n",
    "\n",
    "def Rotten_Tomatoes_Dict(passed_list): \n",
    "    count = {} \n",
    "    for i in passed_list: \n",
    "        for x in i:\n",
    "            count[x] = count.get(x, 0) + 1\n",
    "    return count \n",
    "\n",
    "def Rotten_Tomatoes_Genre_Csv():\n",
    "    movie_genre = []\n",
    "    n = 0\n",
    "    for url in Rotten_Tomatoes_Links():\n",
    "        n = n + 1\n",
    "        page = requests.get(url, headers = headers)\n",
    "        soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "        ref_genre_text = soup.find('div', class_ = 'meta-value genre').text\n",
    "        genre_cleaned = (' '.join(str(ref_genre_text).split()).replace('[', '').replace(']', '').replace('and', ',').replace('Genre(s):',''))\n",
    "        cleaned_text = [n,genre_cleaned]\n",
    "        movie_genre.append(cleaned_text)\n",
    "    return movie_genre    \n",
    "\n",
    "\n",
    "\n",
    "def Rotten_Tomatoes():\n",
    "    rotten_tomatoes = []\n",
    "    rotten_tomatoes = combine(Rotten_Tomatoes_Names(),Rotten_Tomatoes_Genre_Csv())\n",
    "    return rotten_tomatoes\n",
    "\n",
    "def Rotten_Tomatoes_Csv():    \n",
    "    filename = \"Rotten_Tomatoes_top_50.csv\"\n",
    "    headers = ['number', 'name', 'genre']\n",
    "    with open(filename,'w',newline='') as f:  \n",
    "        csvwriter = csv.writer(f, headers) \n",
    "        \n",
    "        #csvwriter writes all the headers and combined movie list with name and genres\n",
    "        csvwriter.writerow(headers)  \n",
    "        csvwriter.writerows(Rotten_Tomatoes()) \n",
    " \n",
    "    print(\"Rotten_Tomatoes_CSV written!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metacritic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Metacritics_Names():\n",
    "    n = 0\n",
    "    url = \"https://www.metacritic.com/browse/movies/score/metascore/all/filtered?sort=desc\"\n",
    "    page = requests.get(url, headers = headers)\n",
    "    soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "    container = soup.find_all('td', class_ = 'clamp-summary-wrap')\n",
    "    movie_names = []\n",
    "    movies = container[:50] #here we get the top 50 movies we want\n",
    "    for movie in movies:\n",
    "        n = n + 1\n",
    "        name = movie.find('h3').text\n",
    "        data = [n, name]\n",
    "        movie_names.append(data)\n",
    "    return movie_names\n",
    "\n",
    "def Metacritics_Links():\n",
    "    n = 0\n",
    "    url = \"https://www.metacritic.com/browse/movies/score/metascore/all/filtered?sort=desc\"\n",
    "    page = requests.get(url, headers = headers)\n",
    "    soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "    container = soup.find_all('td', class_ = 'clamp-summary-wrap')\n",
    "    movie_links = []\n",
    "    movies = container[:50]\n",
    "    for movie in movies:\n",
    "        n = n + 1\n",
    "        tag = movie.find('a', class_ = 'title')\n",
    "        link = tag.get('href', None)\n",
    "        url = \"https://www.metacritic.com\"+link\n",
    "        movie_links.append(url)\n",
    "    return movie_links\n",
    "\n",
    "def Metacritics_Genre_Dict():\n",
    "    metacritic_genre_dict = []\n",
    "    n = 0\n",
    "    for url in Metacritics_Links():\n",
    "        n = n + 1\n",
    "        page = requests.get(url, headers = headers)\n",
    "        soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "        ref_genre_text = soup.find('div', class_ = 'genres').text\n",
    "        genre = ref_genre_text.replace('Genre(s):','').replace(' ','').replace('\\n','').replace(',','\\n').lower().split() \n",
    "        metacritic_genre_dict.append(genre)\n",
    "\n",
    "    return metacritic_genre_dict    \n",
    "\n",
    "def Metacritic_Dictionary(list1): \n",
    "    count = {} \n",
    "    for i in list1: \n",
    "        for x in i:\n",
    "            count[x] = count.get(x, 0) + 1\n",
    "    return count \n",
    "\n",
    "def Metacritics_Genre_Csv():\n",
    "    metacritic_genre_csv = []\n",
    "    n = 0\n",
    "    for url in Metacritics_Links():\n",
    "        n = n + 1\n",
    "        page = requests.get(url, headers = headers)\n",
    "        soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "        ref_genre = soup.find('div', class_ = 'genres').text\n",
    "        ref_genre_clean = (' '.join(str(ref_genre).split()).replace('[', '').replace(']', '').replace('and', ',').replace('Genre(s):',''))\n",
    "        cleaned_text = [n,ref_genre_clean]\n",
    "        metacritic_genre_csv.append(cleaned_text)\n",
    "    return metacritic_genre_csv    \n",
    "\n",
    "        \n",
    "def Metacritics():\n",
    "    metactric = []\n",
    "    metactric = combine(Metacritics_Names(),Metacritics_Genre_Csv())\n",
    "    return metactric   \n",
    "\n",
    "def Metacritics_Csv():    \n",
    "    filename = \"Metactric_top_50.csv\"\n",
    "    #create csv which has headers number,name and genre\n",
    "    headers = ['number', 'name', 'genre']\n",
    "    with open(filename,'w',newline='') as f:  \n",
    "        csvwriter = csv.writer(f, headers) \n",
    "        \n",
    "        #csvwriter writes all the headers and combined movie list with name and genres\n",
    "        csvwriter.writerow(headers)  \n",
    "        csvwriter.writerows(Metacritics())    \n",
    "    print(\"Metacritics_CSV written!\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Cosine_Similarity_between_movie_genre():\n",
    "    \n",
    "    imdb = Imdb_Dict(Fetch_Genre_For_Dict())\n",
    "    rottentomatoes = Rotten_Tomatoes_Dict(Genre_Dict())\n",
    "    metacritic = Metacritic_Dictionary(Metacritics_Genre_Dict())\n",
    "\n",
    "    union_imdb_rottentomatoes = dict(list(imdb.items()) + list(rottentomatoes.items()))\n",
    "    #Fetch values from imdb and rotten tomatoes dictionary and then union both the lists into a dictionary\n",
    "    union_rottentomatoes_metactritic = dict(list(rottentomatoes.items()) + list(metacritic.items()))\n",
    "    #Fetch values from rotten tomatoes and metacritic dictionary and then union both the lists into a dictionary\n",
    "    print(union_imdb_rottentomatoes)\n",
    "    print(union_rottentomatoes_metactritic)\n",
    "    union_sets={'set1': union_imdb_rottentomatoes,'set2': union_rottentomatoes_metactritic}\n",
    "    #store both the sets of the union result in a genre dictionary\n",
    "\n",
    "    def cosine_similarity(x,y):\n",
    "        i1 = {}\n",
    "        i2 = {}\n",
    "        v2 = []\n",
    "        v1 =[]\n",
    "\n",
    "        if len(x) > len(y):\n",
    "            i1 = x\n",
    "            i2 = y\n",
    "        else:\n",
    "            i1 = y\n",
    "            i2 = x\n",
    "            \n",
    "        # Getting vector from dictionary values\n",
    "        v1 = list(i1.values())\n",
    "        for k in i1.keys():    \n",
    "            if k in i2:\n",
    "                v2.append(float(i2[k]))\n",
    "            else :\n",
    "                v2.append(float(0))\n",
    "        #operations based on cosine formula\n",
    "        numerator = sum(a*b for a,b in zip(v2,v1))\n",
    "        denominator = round(sqrt(sum([a*a for a in v1])),3)*round(sqrt(sum([a*a for a in v2])),3)\n",
    "        return round(numerator/float(denominator),3)\n",
    "\n",
    "    print(\"The 3 Websites have a cosine similarity of : \")\n",
    "    print (cosine_similarity(union_sets['set1'],union_sets['set2']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def db_connection():\n",
    "    con = sqlite3.connect(\"Top50.db\")#this opens the Top50 database, if it does not exist, it will create a new one\n",
    "#it can also connect to remote databases, but we are just doing it on our local server\n",
    "    if(con):\n",
    "        print(\"Established Connection Successfully\")#if connection is successful then print success\n",
    "    else:\n",
    "        print(\"Connection Error\")#print error if connection is not possible    \n",
    "    cur = con.cursor() #cursor reads the database, like open() when we are dealing with files\n",
    "    \n",
    "    cur.execute('DROP TABLE IF EXISTS IMDB')#drop table if IMDB table already exists\n",
    "    cur.execute(\"CREATE TABLE IMDB (number, name, genre)\")#create a table IMDB which has 3columns i.e. number,name and genre\n",
    " \n",
    "    with open('Top50_Imdb_movie.csv','r') as file_input:# open csv in read mode\n",
    "        dict_read = csv.DictReader(file_input) \n",
    "        db_inp = [(i['number'],i['name'], i['genre'])  for i in dict_read]\n",
    "     #for all values read by csv create columns of number, name and genre and give as input to the database   \n",
    "    insert_intodb = cur.executemany(\"INSERT INTO IMDB ( number, name, genre) VALUES ( ?, ?, ?);\", db_inp)\n",
    "    #Insert query into the IMDB table which takes all the values\n",
    "    cur.execute('DROP TABLE IF EXISTS Rotten_Tomatoes')\n",
    "    #drop table if Rotten_Tomatoes table already exists\n",
    "    cur.execute(\"CREATE TABLE Rotten_Tomatoes (number, name, genre)\")\n",
    "    #create a table Rotten_Tomatoes which has 3columns\n",
    "    with open('Rotten_Tomatoes_top_50.csv','r') as file_input:\n",
    "      # open csv in read mode\n",
    "        dict_read = csv.DictReader(file_input) \n",
    "        db_inp = [(i['number'],i['name'], i['genre'])  for i in dict_read]\n",
    "    #for all values read by csv create columns of number, name and genre and give as input to the database\n",
    "    insert_intodb  = cur.executemany(\"INSERT INTO Rotten_Tomatoes ( number, name, genre) VALUES ( ?, ?, ?);\", db_inp)\n",
    "    #Insert query into the Rotten_Tomatoes table which takes all the values\n",
    "    cur.execute('DROP TABLE IF EXISTS Metacritic')\n",
    "     #drop table if Metacritic table already exists\n",
    "    cur.execute(\"CREATE TABLE Metacritic (number, name, genre)\")\n",
    "    #create a table Metacritic which has 3columns\n",
    "    with open('Metactric_top_50.csv','r') as file_input:\n",
    "      # open csv in read mode\n",
    "        dict_read = csv.DictReader(file_input) \n",
    "        db_inp = [(i['number'],i['name'], i['genre'])  for i in dict_read]\n",
    "    #for all values read by csv create columns of number, name and genre and give as input to the database\n",
    "    insert_intodb  = cur.executemany(\"INSERT INTO Metacritic ( number, name, genre) VALUES ( ?, ?, ?);\", db_inp)\n",
    "    #Insert query into the Metacritic table which takes all the values\n",
    "    if(insert_intodb ):\n",
    "        print(\"Successfully added\")\n",
    "    else:\n",
    "        print(\"Error\")    \n",
    "    con.commit() #we need to commit it to save it, just like office files\n",
    "    con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imdb_CSV written!\n",
      "Rotten_Tomatoes_CSV written!\n",
      "Metacritics_CSV written!\n",
      "Established Connection Successfully\n",
      "Successfully added\n",
      "{'drama': 21, 'crime': 5, 'action': 10, 'thriller': 7, 'biography': 5, 'history': 2, 'adventure': 14, 'fantasy': 13, 'western': 2, 'romance': 4, 'sci-fi': 8, 'mystery': 7, 'comedy': 18, 'war': 2, 'family': 8, 'animation': 5, 'musical': 2, 'music': 2, 'horror': 4, 'scifi': 5, 'kids': 8}\n",
      "{'fantasy': 3, 'action': 3, 'adventure': 3, 'scifi': 5, 'horror': 3, 'mystery': 10, 'thriller': 13, 'kids': 8, 'family': 3, 'animation': 3, 'comedy': 9, 'drama': 39, 'musical': 3, 'crime': 4, 'music': 1, 'romance': 11, 'war': 5, 'history': 5, 'film-noir': 4, 'western': 2, 'sport': 1, 'documentary': 1, 'biography': 2}\n",
      "The 3 Websites have a cosine similarity of : \n",
      "0.79\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    Imdb_Csv()\n",
    "    Rotten_Tomatoes_Csv()\n",
    "    Metacritics_Csv()\n",
    "    db_connection()\n",
    "    Cosine_Similarity_between_movie_genre()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
